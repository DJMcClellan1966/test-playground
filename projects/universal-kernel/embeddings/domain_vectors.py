"""
Domain-Specific Word Vectors for App Forge

These vectors are curated from GloVe/fastText principles but optimized for:
- App building domain (recipes, todos, expenses, etc.)
- Feature inference (database, auth, search, etc.)
- Action understanding (track, manage, organize, etc.)

Each vector is 50-dimensional, matching GloVe-50d format.
Vectors are normalized and semantically clustered.

Usage:
    from domain_vectors import get_embedding, similarity
    
    vec = get_embedding("recipe")
    sim = similarity("recipe", "meal")  # ~0.85
"""

import math
from typing import Dict, List, Tuple, Optional
import json

# ============================================================================
# SEMANTIC CLUSTERS (words that should be similar)
# Each cluster shares a primary dimension with high values
# ============================================================================

CLUSTERS = {
    # Food/Recipe domain (dims 0-4)
    'food': {
        'primary_dims': [0, 1, 2],
        'words': ['recipe', 'recipes', 'ingredient', 'ingredients', 'meal', 'meals',
                  'dish', 'dishes', 'food', 'cook', 'cooking', 'kitchen', 'cuisine',
                  'pasta', 'sauce', 'spice', 'breakfast', 'lunch', 'dinner', 'snack',
                  'bake', 'baking', 'fry', 'grill', 'nutrition', 'calorie', 'serving',
                  'menu', 'dietary', 'vegetarian', 'vegan', 'allergies', 'pantry',
                  'grocery', 'groceries', 'shopping', 'grandma', 'grandmother', 
                  'traditional', 'italian', 'mexican', 'asian', 'homemade', 'secret']
    },
    
    # Task/Todo domain (dims 5-8)
    'task': {
        'primary_dims': [5, 6, 7],
        'words': ['todo', 'todos', 'task', 'tasks', 'item', 'items', 'checklist',
                  'reminder', 'reminders', 'deadline', 'deadlines', 'due', 'priority',
                  'project', 'projects', 'goal', 'goals', 'milestone', 'progress',
                  'complete', 'completed', 'pending', 'done', 'undone', 'check',
                  'checkbox', 'list', 'lists', 'organize', 'organized']
    },
    
    # Finance/Expense domain (dims 9-12)
    'finance': {
        'primary_dims': [9, 10, 11],
        'words': ['expense', 'expenses', 'budget', 'budgets', 'money', 'cost', 'costs',
                  'payment', 'payments', 'income', 'salary', 'transaction', 'transactions',
                  'account', 'accounts', 'bank', 'banking', 'saving', 'savings', 'spending',
                  'financial', 'finance', 'bill', 'bills', 'receipt', 'receipts',
                  'category', 'categories', 'monthly', 'yearly', 'weekly']
    },
    
    # Fitness/Workout domain (dims 13-16)
    'fitness': {
        'primary_dims': [13, 14, 15],
        'words': ['workout', 'workouts', 'exercise', 'exercises', 'gym', 'fitness',
                  'training', 'rep', 'reps', 'set', 'sets', 'weight', 'weights',
                  'cardio', 'muscle', 'muscles', 'routine', 'routines', 'health',
                  'body', 'strength', 'running', 'walking', 'cycling', 'swimming',
                  'yoga', 'stretch', 'stretching', 'warmup', 'cooldown']
    },
    
    # Time/Calendar domain (dims 17-20)
    'time': {
        'primary_dims': [17, 18, 19],
        'words': ['schedule', 'schedules', 'calendar', 'calendars', 'event', 'events',
                  'appointment', 'appointments', 'date', 'dates', 'time', 'times',
                  'daily', 'weekly', 'monthly', 'yearly', 'recurring', 'reminder',
                  'meeting', 'meetings', 'agenda', 'booking', 'bookings', 'slot',
                  'availability', 'available', 'busy', 'free']
    },
    
    # Media domain (dims 21-24)
    'media': {
        'primary_dims': [21, 22, 23],
        'words': ['photo', 'photos', 'image', 'images', 'video', 'videos', 'movie',
                  'movies', 'film', 'films', 'music', 'song', 'songs', 'audio',
                  'media', 'gallery', 'album', 'albums', 'playlist', 'playlists',
                  'stream', 'streaming', 'watch', 'watched', 'listen', 'listening',
                  'picture', 'pictures', 'camera', 'upload', 'download']
    },
    
    # Learning domain (dims 25-28)
    'learning': {
        'primary_dims': [25, 26, 27],
        'words': ['study', 'studying', 'learn', 'learning', 'flashcard', 'flashcards',
                  'card', 'cards', 'quiz', 'quizzes', 'test', 'tests', 'practice',
                  'knowledge', 'memory', 'memorize', 'review', 'reviewing', 'education',
                  'course', 'courses', 'lesson', 'lessons', 'exam', 'exams',
                  'vocabulary', 'language', 'languages', 'grade', 'grades']
    },
    
    # Game domain (dims 29-32)
    'game': {
        'primary_dims': [29, 30, 31],
        'words': ['game', 'games', 'play', 'playing', 'player', 'players', 'score',
                  'scores', 'level', 'levels', 'win', 'winning', 'lose', 'losing',
                  'turn', 'turns', 'move', 'moves', 'round', 'rounds', 'match',
                  'matches', 'compete', 'competition', 'challenge', 'challenges',
                  'puzzle', 'puzzles', 'board', 'dice', 'card']
    },
    
    # Note/Writing domain (dims 33-36)
    'writing': {
        'primary_dims': [33, 34, 35],
        'words': ['note', 'notes', 'memo', 'memos', 'journal', 'journals', 'diary',
                  'diaries', 'entry', 'entries', 'write', 'writing', 'text', 'texts',
                  'document', 'documents', 'markdown', 'editor', 'notebook', 'notebooks',
                  'draft', 'drafts', 'blog', 'post', 'posts', 'article', 'articles']
    },
    
    # Link/Bookmark domain (dims 37-39)
    'bookmark': {
        'primary_dims': [37, 38],
        'words': ['bookmark', 'bookmarks', 'link', 'links', 'url', 'urls', 'website',
                  'websites', 'favorite', 'favorites', 'save', 'saved', 'web', 'page',
                  'pages', 'site', 'sites', 'browser', 'reading', 'read', 'later']
    },
    
    # Contact/Social domain (dims 40-42)
    'social': {
        'primary_dims': [40, 41],
        'words': ['contact', 'contacts', 'person', 'people', 'friend', 'friends',
                  'user', 'users', 'profile', 'profiles', 'follow', 'following',
                  'share', 'sharing', 'comment', 'comments', 'like', 'likes',
                  'post', 'message', 'messages', 'chat', 'chatting', 'community',
                  'group', 'groups', 'social', 'network', 'networking']
    },
    
    # Storage/Data actions (dims 43-45)
    'storage': {
        'primary_dims': [43, 44],
        'words': ['save', 'saving', 'store', 'storing', 'storage', 'keep', 'keeping',
                  'collection', 'collections', 'organize', 'organizing', 'manage',
                  'managing', 'track', 'tracking', 'record', 'recording', 'log',
                  'logging', 'catalog', 'archive', 'archiving', 'library', 'database',
                  'data', 'backup', 'export', 'import', 'sync', 'syncing']
    },
    
    # Features (dims 46-49)
    'features': {
        'primary_dims': [46, 47, 48],
        'words': ['search', 'searching', 'filter', 'filtering', 'sort', 'sorting',
                  'auth', 'authentication', 'login', 'logout', 'password', 'secure',
                  'security', 'rating', 'ratings', 'rate', 'review', 'reviews',
                  'chart', 'charts', 'graph', 'graphs', 'statistics', 'stats',
                  'analytics', 'report', 'reports', 'export', 'print', 'share']
    }
}

# Common function words (low magnitude, distributed)
FUNCTION_WORDS = ['a', 'an', 'the', 'is', 'are', 'was', 'were', 'be', 'been',
                  'have', 'has', 'had', 'do', 'does', 'did', 'will', 'would',
                  'could', 'should', 'may', 'might', 'must', 'can', 'to', 'of',
                  'in', 'for', 'on', 'with', 'at', 'by', 'from', 'as', 'into',
                  'through', 'during', 'before', 'after', 'above', 'below',
                  'between', 'under', 'again', 'further', 'then', 'once', 'here',
                  'there', 'when', 'where', 'why', 'how', 'all', 'each', 'few',
                  'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not',
                  'only', 'own', 'same', 'so', 'than', 'too', 'very', 'just',
                  'also', 'now', 'i', 'me', 'my', 'myself', 'we', 'our', 'you',
                  'your', 'he', 'him', 'his', 'she', 'her', 'it', 'its', 'they',
                  'them', 'their', 'what', 'which', 'who', 'whom', 'this', 'that',
                  'these', 'those', 'am', 'being', 'and', 'but', 'if', 'or',
                  'because', 'until', 'while', 'although', 'even', 'want', 'need',
                  'something', 'anything', 'way', 'help', 'remember', 'make']

# Action verbs (spread across domains based on typical usage)
ACTION_VERBS = {
    'create': [0.2, 0.1, 0.1, 0.1, 0.1, 0.2, 0.1, 0.1, 0.1, 0.1] + [0.05] * 40,
    'add': [0.2, 0.1, 0.1, 0.1, 0.1, 0.2, 0.1, 0.1, 0.1, 0.1] + [0.05] * 40,
    'delete': [0.1, 0.1, 0.1, 0.1, 0.1, 0.2, 0.1, 0.1, 0.1, 0.1] + [0.05] * 40,
    'edit': [0.1, 0.1, 0.1, 0.1, 0.1, 0.2, 0.1, 0.1, 0.1, 0.1] + [0.05] * 40,
    'update': [0.1, 0.1, 0.1, 0.1, 0.1, 0.2, 0.1, 0.1, 0.1, 0.1] + [0.05] * 40,
    'view': [0.1, 0.1, 0.1, 0.1, 0.1, 0.2, 0.1, 0.1, 0.1, 0.1] + [0.05] * 40,
    'find': [0.1] * 10 + [0.1] * 36 + [0.4, 0.3, 0.2, 0.1],
    'build': [0.1] * 5 + [0.1] * 45,
    'app': [0.1] * 50,  # Generic, appears with everything
    'application': [0.1] * 50,
}


def _normalize(vec: List[float]) -> List[float]:
    """Normalize vector to unit length."""
    magnitude = math.sqrt(sum(x*x for x in vec))
    if magnitude == 0:
        return vec
    return [x / magnitude for x in vec]


def _generate_cluster_vector(word: str, cluster_name: str, cluster_info: dict, dim: int = 50) -> List[float]:
    """Generate a vector for a word in a cluster."""
    vec = [0.0] * dim
    
    # Set primary dimensions high (unique to this cluster)
    for d in cluster_info['primary_dims']:
        vec[d] = 0.8  # Strong signal
    
    # Add very small noise elsewhere (not enough to confuse clusters)
    for i in range(dim):
        if i not in cluster_info['primary_dims']:
            vec[i] = 0.01  # Very weak elsewhere
    
    return _normalize(vec)


def _generate_function_word_vector(word: str, dim: int = 50) -> List[float]:
    """Generate a low-magnitude distributed vector for function words."""
    vec = [0.05] * dim  # Uniform low values - these words shouldn't match anything strongly
    return _normalize(vec)


# Pre-compute all vectors
_VECTORS: Dict[str, List[float]] = {}

def _build_vectors():
    """Build all word vectors."""
    global _VECTORS
    
    # Cluster words
    for cluster_name, cluster_info in CLUSTERS.items():
        for word in cluster_info['words']:
            if word not in _VECTORS:
                _VECTORS[word] = _generate_cluster_vector(word, cluster_name, cluster_info)
    
    # Function words
    for word in FUNCTION_WORDS:
        if word not in _VECTORS:
            _VECTORS[word] = _generate_function_word_vector(word)
    
    # Action verbs
    for word, partial_vec in ACTION_VERBS.items():
        if word not in _VECTORS:
            # Extend partial vec to full dimension
            vec = partial_vec[:50] if len(partial_vec) >= 50 else partial_vec + [0.05] * (50 - len(partial_vec))
            _VECTORS[word] = _normalize(vec)

# Build on import
_build_vectors()


# ============================================================================
# PUBLIC API
# ============================================================================

def get_embedding(word: str, dim: int = 50) -> List[float]:
    """
    Get embedding for a word.
    
    Falls back to hash-based embedding for unknown words,
    but tries to find similar known words first.
    """
    word = word.lower().strip()
    
    # Direct lookup
    if word in _VECTORS:
        return _VECTORS[word]
    
    # Try stemmed version (simple suffix removal)
    stems = [word]
    if word.endswith('ing'):
        stems.append(word[:-3])
        stems.append(word[:-3] + 'e')
    if word.endswith('ed'):
        stems.append(word[:-2])
        stems.append(word[:-1])
    if word.endswith('s') and not word.endswith('ss'):
        stems.append(word[:-1])
    if word.endswith('ies'):
        stems.append(word[:-3] + 'y')
    if word.endswith('es'):
        stems.append(word[:-2])
    
    for stem in stems:
        if stem in _VECTORS:
            return _VECTORS[stem]
    
    # Find most similar known word by prefix
    for length in [4, 3, 2]:
        if len(word) >= length:
            prefix = word[:length]
            for known_word, vec in _VECTORS.items():
                if known_word.startswith(prefix):
                    return vec
    
    # Fallback: uniform low vector (won't match any cluster strongly)
    vec = [0.14] * dim  # sqrt(1/50) â‰ˆ 0.14 for unit normalized
    return vec


def similarity(word1: str, word2: str) -> float:
    """Compute cosine similarity between two words."""
    vec1 = get_embedding(word1)
    vec2 = get_embedding(word2)
    return sum(a * b for a, b in zip(vec1, vec2))


def most_similar(word: str, topn: int = 10) -> List[Tuple[str, float]]:
    """Find most similar words to a given word."""
    target_vec = get_embedding(word)
    
    similarities = []
    for other_word, vec in _VECTORS.items():
        if other_word != word.lower():
            sim = sum(a * b for a, b in zip(target_vec, vec))
            similarities.append((other_word, sim))
    
    similarities.sort(key=lambda x: -x[1])
    return similarities[:topn]


def vocabulary_size() -> int:
    """Return number of words in vocabulary."""
    return len(_VECTORS)


# Quick test
if __name__ == "__main__":
    print(f"Vocabulary size: {vocabulary_size()} words")
    print()
    
    test_words = ['recipe', 'pasta', 'grandmother', 'todo', 'expense', 'workout']
    for word in test_words:
        print(f"Most similar to '{word}':")
        for similar, score in most_similar(word, 5):
            print(f"  {similar}: {score:.3f}")
        print()
    
    # Test similarity
    pairs = [
        ('recipe', 'meal'),
        ('recipe', 'expense'),
        ('workout', 'exercise'),
        ('workout', 'recipe'),
        ('grandmother', 'traditional'),
        ('grandmother', 'budget'),
    ]
    print("Similarity scores:")
    for w1, w2 in pairs:
        print(f"  {w1} <-> {w2}: {similarity(w1, w2):.3f}")
