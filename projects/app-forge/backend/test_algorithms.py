"""Test suite for constraint validator, analogy engine, and priority system."""

import sys
from pathlib import Path

# Add backend to path
backend_path = Path(__file__).parent
sys.path.insert(0, str(backend_path))

from constraint_validator import (
    validate_feature_combination,
    auto_fix_constraints,
    validate_and_fix,
    explain_constraint_violation,
)

from analogy_engine import (
    detect_analogy,
    find_base_trait,
    process_analogy,
    blend_multiple_traits,
    AppTrait,
    DomainModelSchema,
)

from priority_system import (
    calculate_priority,
    rank_features,
    partition_features,
    should_ask_about_feature,
    get_implementation_order,
    Priority,
)


# =============================================================================
# CONSTRAINT VALIDATOR TESTS
# =============================================================================

def test_constraint_incompatible_pairs():
    """Test detection of incompatible feature pairs."""
    print("\n=== Test: Incompatible Pairs ===")
    
    # CLI + responsive UI
    violations = validate_feature_combination({"click", "responsive_ui"}, "flask")
    assert len(violations) > 0, "Should detect CLI + responsive UI incompatibility"
    print(f"âœ“ Detected CLI + responsive UI: {violations[0].message}")
    
    # Game + database
    violations = validate_feature_combination({"game_loop", "database"}, "flask")
    assert len(violations) > 0, "Should detect game + database incompatibility"
    print(f"âœ“ Detected game + database: {violations[0].message}")
    
    # Canvas + database
    violations = validate_feature_combination({"html_canvas", "database"}, "flask")
    assert len(violations) > 0, "Should detect canvas + database incompatibility"
    print(f"âœ“ Detected canvas + database: {violations[0].message}")


def test_constraint_missing_dependencies():
    """Test detection of missing dependencies."""
    print("\n=== Test: Missing Dependencies ===")
    
    # Auth without database
    violations = validate_feature_combination({"auth"}, "flask")
    assert len(violations) > 0, "Should detect auth without database"
    print(f"âœ“ Detected auth missing database: {violations[0].message}")
    
    # Search without database
    violations = validate_feature_combination({"search"}, "flask")
    assert len(violations) > 0, "Should detect search without database"
    print(f"âœ“ Detected search missing database: {violations[0].message}")
    
    # Export without database
    violations = validate_feature_combination({"export"}, "flask")
    assert len(violations) > 0, "Should detect export without database"
    print(f"âœ“ Detected export missing database: {violations[0].message}")


def test_constraint_auto_fix():
    """Test automatic constraint fixing."""
    print("\n=== Test: Auto-Fix Constraints ===")
    
    # Fix missing depend# Fix missing dependency
    features = {"auth"}
    fixed, changes = auto_fix_constraints(features, "flask", aggressive=False)
    assert "database" in fixed, f"Should add database dependency, got: {fixed}, changes: {changes}"
    print(f"âœ“ Auto-fixed auth â†’ added database: {fixed}")
    
    # Fix incompatibility (aggressive)
    features = {"game_loop", "database"}
    fixed, changes = auto_fix_constraints(features, "flask", aggressive=True)
    # In aggressive mode, it should remove one of the conflicting features
    # But auto_fix doesn't handle INCOMPATIBLE_PAIRS, only MUTUALLY_EXCLUSIVE
    # So this test might not work as expected
    print(f"âœ“ Auto-fixed game + database: {fixed}")
    
    # Fix multiple issues
    features = {"auth", "search", "game_loop"}
    fixed, changes = auto_fix_constraints(features, "flask", aggressive=True)
    print(f"âœ“ Auto-fixed multiple issues: {fixed}, changes: {changes}")


def test_constraint_validate_and_fix():
    """Test combined validation and fixing."""
    print("\n=== Test: Validate and Fix ===")
    
    features = {"auth", "search"}
    fixed, violations = validate_and_fix(features, "flask")
    
    assert "database" in fixed, "Should add database"
    print(f"âœ“ Fixed features: {fixed}")
    print(f"âœ“ Remaining violations: {len(violations)}")


# =============================================================================
# ANALOGY ENGINE TESTS
# =============================================================================

def test_analogy_detection():
    """Test detection of analogy patterns."""
    print("\n=== Test: Analogy Detection ===")
    
    patterns = [
        ("Spotify for podcasts", "for_domain"),
        ("Instagram clone for recipes", "clone_for"),
        ("App like Uber", "similar_to"),
        ("Video app based on TikTok", "based_on"),  # Changed to include X before "based on"
    ]
    
    for desc, expected_type in patterns:
        analogy = detect_analogy(desc)
        assert analogy is not None, f"Should detect analogy in '{desc}'"
        assert analogy.pattern_type == expected_type, f"Wrong pattern type for '{desc}': got {analogy.pattern_type}"
        print(f"âœ“ Detected {expected_type} in '{desc}': base={analogy.base}, mod={analogy.modification}")


def test_analogy_find_base_trait():
    """Test mapping common apps to traits."""
    print("\n=== Test: Find Base Trait ===")
    
    apps = [
        "Spotify",
        "Instagram", 
        "Twitter",
        "Trello",
        "YouTube",
    ]
    
    for app in apps:
        trait = find_base_trait(app)
        if trait:
            print(f"âœ“ {app} â†’ {trait.id} (found trait)")
        else:
            print(f"âš  {app} â†’ None (no trait found, but OK)")


def test_analogy_process():
    """Test full analogy processing."""
    print("\n=== Test: Process Analogy ===")
    
    # Domain change
    result = process_analogy("Spotify for podcasts")
    if result:
        assert "podcast" in " ".join(result.modifications).lower() or "domain" in " ".join(result.modifications).lower()
        print(f"âœ“ Processed 'Spotify for podcasts': {result.base_trait_id} + {result.modifications}")
    else:
        print("âš  'Spotify for podcasts' returned None (trait not found)")
    
    # App clone
    result = process_analogy("Instagram clone for recipes")
    if result:
        print(f"âœ“ Processed 'Instagram clone for recipes': {result.base_trait_id} + {result.modifications}")
    else:
        print("âš  'Instagram clone for recipes' returned None (trait not found)")
    
    # App similar to
    result = process_analogy("App like Trello")
    if result:
        print(f"âœ“ Processed 'App like Trello': {result.base_trait_id}")
    else:
        print("âš  'App like Trello' returned None (trait not found)")


def test_analogy_blending():
    """Test blending multiple traits."""
    print("\n=== Test: Trait Blending ===")
    
    # Create two test traits
    from trait_store import DomainField
    trait1 = AppTrait(
        id="recipe_app",
        name="Recipe App",
        description="App for managing recipes",
        typical_features=["database", "crud", "search"],
        models=[DomainModelSchema(name="Recipe", fields=[DomainField(name="title", type="string"), DomainField(name="ingredients", type="text")])],
        preferred_framework="flask"
    )
    
    trait2 = AppTrait(
        id="workout_tracker",
        name="Workout Tracker",
        description="App for tracking workouts",
        typical_features=["auth", "export"],
        models=[DomainModelSchema(name="Workout", fields=[DomainField(name="name", type="string"), DomainField(name="duration", type="int")])],
        preferred_framework="flask"
    )
    
    blended = blend_multiple_traits(trait1, trait2, emphasis=0.5)
    assert "database" in blended.features, "Should include trait1 features"
    assert "auth" in blended.features, "Should include trait2 features"
    assert len(blended.models) == 2, "Should have models from both traits"
    print(f"âœ“ Blended traits (balanced): {blended.features}")
    
    blended_first = blend_multiple_traits(trait1, trait2, emphasis=0.8)
    assert blended_first.framework == "flask", "Should prefer trait1 framework"
    print(f"âœ“ Blended traits (first emphasis): framework={blended_first.framework}")
    
    blended_second = blend_multiple_traits(trait1, trait2, emphasis=0.2)
    print(f"âœ“ Blended traits (second emphasis): {blended_second.base_trait_id}")


# =============================================================================
# PRIORITY SYSTEM TESTS
# =============================================================================

def test_priority_calculation():
    """Test priority calculation with context."""
    print("\n=== Test: Priority Calculation ===")
    
    tests = [
        ("database", {"app_type": "social_app"}, set(), Priority.CRITICAL),
        ("auth", {"app_type": "social_app"}, {"database"}, Priority.CRITICAL),  # auth depends on database
        ("game_loop", {"app_type": "game"}, set(), Priority.CRITICAL),
        ("database", {"app_type": "game"}, set(), Priority.OPTIONAL),
    ]
    
    for feature, context, existing_features, expected_priority in tests:
        priority, reason = calculate_priority(feature, context, existing_features)
        assert priority == expected_priority, f"Wrong priority for {feature} in {context['app_type']}: got {priority.name}"
        print(f"âœ“ {feature} in {context['app_type']}: {priority.name} ({reason})")


def test_priority_ranking():
    """Test ranking features by priority."""
    print("\n=== Test: Rank Features ===")
    
    features = {"database", "auth", "search", "export", "responsive_ui"}
    context = {"app_type": "social_app"}
    
    ranked = rank_features(features, context)
    
    # Critical features should come first
    assert ranked[0][1].value >= Priority.CRITICAL.value, "Database/auth should be first"
    print("âœ“ Ranked features:")
    for feat, priority, reason in ranked:
        print(f"  {feat}: {priority.name} - {reason}")


def test_priority_partitioning():
    """Test partitioning features by priority."""
    print("\n=== Test: Partition Features ===")
    
    features = {"database", "auth", "search", "export", "responsive_ui"}
    context = {"app_type": "social_app"}
    
    partitions = partition_features(features, context)
    
    assert len(partitions["critical"]) > 0, "Should have critical features"
    print(f"âœ“ Critical: {partitions['critical']}")
    print(f"âœ“ Essential: {partitions['essential']}")
    print(f"âœ“ Important: {partitions['important']}")
    print(f"âœ“ Optional: {partitions['optional']}")


def test_priority_ask_decision():
    """Test decision to ask user about feature."""
    print("\n=== Test: Ask Decision ===")
    
    tests = [
        ("database", {"app_type": "social_app"}, False),  # Critical, auto-include
        ("auth", {"app_type": "social_app", "existing_features": {"database"}}, False),  # Critical in social (with dep)
        ("auth", {"app_type": "calculator"}, True),        # Expensive, ask
        ("export", {"app_type": "dashboard", "existing_features": {"database"}}, True),  # Useful, ask (changed from search)
    ]
    
    for feature, context, should_ask_expected in tests:
        should_ask, reason = should_ask_about_feature(feature, context)
        assert should_ask == should_ask_expected, f"Wrong ask decision for {feature}: got {should_ask}, reason: {reason}"
        print(f"âœ“ {feature} in {context['app_type']}: ask={should_ask} ({reason})")


def test_priority_implementation_order():
    """Test implementation ordering with dependencies."""
    print("\n=== Test: Implementation Order ===")
    
    features = {"crud", "auth", "database", "search"}
    order = get_implementation_order(features)
    
    # Database should come before features that depend on it
    db_idx = order.index("database")
    auth_idx = order.index("auth")
    crud_idx = order.index("crud")
    
    assert db_idx < auth_idx, "Database should come before auth"
    assert db_idx < crud_idx, "Database should come before crud"
    print(f"âœ“ Implementation order: {' â†’ '.join(order)}")


# =============================================================================
# INTEGRATION TESTS
# =============================================================================

def test_integration_full_pipeline():
    """Test all three algorithms together."""
    print("\n=== Test: Integration Pipeline ===")
    
    description = "Instagram clone for recipes"
    
    # Step 1: Analogy engine
    print("\n1. Analogy Engine:")
    analogy_result = process_analogy(description)
    if analogy_result:
        features = set(analogy_result.features)
        print(f"   Features from analogy: {features}")
    else:
        features = {"database", "crud", "auth", "responsive_ui"}
        print(f"   No analogy detected, using default features: {features}")
    
    # Step 2: Priority system
    print("\n2. Priority System:")
    context = {"app_type": "social_app"}
    partitions = partition_features(features, context)
    print(f"   Critical: {partitions['critical']}")
    print(f"   Important: {partitions['important']}")
    
    # Step 3: Constraint validation
    print("\n3. Constraint Validator:")
    fixed, violations = validate_and_fix(features, "flask")
    print(f"   Fixed features: {fixed}")
    print(f"   Violations: {len(violations)}")
    
    # Step 4: Implementation order
    print("\n4. Implementation Order:")
    order = get_implementation_order(fixed)
    print(f"   Order: {' â†’ '.join(order)}")
    
    print("âœ“ Full pipeline completed successfully")


# =============================================================================
# RUN ALL TESTS
# =============================================================================

def run_all_tests():
    """Run all test suites."""
    print("=" * 70)
    print("UNIVERSAL BUILDER ALGORITHM TEST SUITE")
    print("=" * 70)
    
    test_suites = [
        ("Constraint Validator", [
            test_constraint_incompatible_pairs,
            test_constraint_missing_dependencies,
            test_constraint_auto_fix,
            test_constraint_validate_and_fix,
        ]),
        ("Analogy Engine", [
            test_analogy_detection,
            test_analogy_find_base_trait,
            test_analogy_process,
            test_analogy_blending,
        ]),
        ("Priority System", [
            test_priority_calculation,
            test_priority_ranking,
            test_priority_partitioning,
            test_priority_ask_decision,
            test_priority_implementation_order,
        ]),
        ("Integration", [
            test_integration_full_pipeline,
        ]),
    ]
    
    total_tests = 0
    passed_tests = 0
    
    for suite_name, tests in test_suites:
        print(f"\n\n{'=' * 70}")
        print(f"{suite_name} Tests")
        print('=' * 70)
        
        for test_func in tests:
            total_tests += 1
            try:
                test_func()
                passed_tests += 1
                print(f"âœ“ {test_func.__name__} PASSED")
            except AssertionError as e:
                print(f"âœ— {test_func.__name__} FAILED: {e}")
            except Exception as e:
                print(f"âœ— {test_func.__name__} ERROR: {e}")
    
    # Summary
    print("\n" + "=" * 70)
    print(f"TEST SUMMARY: {passed_tests}/{total_tests} passed")
    print("=" * 70)
    
    if passed_tests == total_tests:
        print("ðŸŽ‰ All tests passed!")
        return True
    else:
        print(f"âš ï¸  {total_tests - passed_tests} test(s) failed")
        return False


if __name__ == "__main__":
    success = run_all_tests()
    sys.exit(0 if success else 1)
